### 神经网络

#### 1.感知机
##### 感知机图示
![感知器图示](https://github.com/ZWtu19/Notes/blob/master/src/pics/感知机图示.png)  
* 组成 : 输入层 -> 输出层  
    其中输入层为信号,从输入层到输出层需要经过权重W的组合计算  


#### 2.神经网络
##### 神经网络图示
![神经网络图示](https://github.com/ZWtu19/Notes/blob/master/src/pics/神经网络图示.png)

##### 神经网络的组成  
* 基本组成 : 输入层 -> 隐层 -> 输出层  
    1. 其中隐层对输入层的数据进行处理,各层之间需要经过权重W和输入的计算,以及不同函数的处理;  
    2. 注意神经网络的层数由具有权重的层数决定,有几层具有权重,即神经网络的层数为几层;  
    
* 计算过程   
![计算过程图示](https://github.com/ZWtu19/Notes/blob/master/src/pics/激活函数计算过程.png)
    1. 组合权重W和偏置B求和(以两层为例) : a = W1 * x1 + W2 * x2 + b
    2. 利用激活函数求得结果 : y = h(a)  
    
* 激活函数: h(x)  
    1. 阶跃函数
	    1. 图示  
	    ![跃迁函数图示](https://github.com/ZWtu19/Notes/blob/master/src/pics/跃迁函数.png)
	    2. 函数表达式为：h(x) =   
	    3. 在Python中的实现方式：      
    2. sigmoid函数 
	    1. 图示  
	    ![sigmoid函数](https://github.com/ZWtu19/Notes/blob/master/src/pics/sigmoid函数.png)
	    2. 函数表达式为：h(x) = 1/( 1+exp(-x) )  
	    3. 在Python中实现方式： 
        ```python
        # 其中np为Numpy, x 可以为Numpy数组
            import numpy as np
            def sigmoid(x):
                    return 1/(1+np.exp(-x))
        ```

    3. 二者异同之处:   
	    1. 共同点：宏观角度来看，形状相似，即当输入信号为重要信息时，
阶跃函数和sigmoid函数都会输出较大的值；当输入信号为不重要的信息时，
两者都输出较小的值；两者均为非线性函数，注意激活函数必须为非线性函数，否则神经网络分层就没有意义了；
	    2. 区别： 平滑性不同；阶跃函数只能输出0/1，sigmoid能输出连续的实数； 
    4. ReLu函数：  
    	1. 图示：  
	    2. 函数的表达式： 
	    3. 在Python中的实现方式  
	    
* 神经网络的信号传递实现三层为例)  
    1. 符号说明  
    ![权重符号说明](https://github.com/ZWtu19/Notes/blob/master/src/pics/权重符号说明.png)    
    2. 输入层 -> 第一层  
        1. 表达式    
        a1 = w11 * x1 + w12 * x2 + b1;
        a2 = w21 * x1 + w22 * x2 + b2;  
        a3 = w31 * x1 + w22 * x2 + b3;    
        z1 = h(a1);  
        z2 = h(a2);  
        z3 = h(a3);  
        
        2. 图示说明  
        ![图示说明](https://github.com/ZWtu19/Notes/blob/master/src/pics/输入层->第一层.png)
        3. 矩阵表示  
        A = XW + B  
        Z = h(A)  
        其中:  
        A = [a1, a2, a3];  
        X = [x1, x2];  
        B = [b1, b2, b3];  
        w = [[w11, w21, w31],
             [w12, w22, w32]]  
        4. 代码实现  
        ```python
            import numpy as np
            X = np.array([1.0, 0.5])
            W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]]) B1 = np.array([0.1, 0.2, 0.3])
            print(W1.shape) # (2, 3) print(X.shape) # (2,) print(B1.shape) # (3,)
            A1 = np.dot(X, W1) + B1
        ```  
    3. 第一层 -> 第二层  
        1. 表达式  
        a1' = w'11 * z1 + w'12 * z2 + w'13 * z3 + b'1;
        a2' = w'21 * z1 + w'22 * z2 + w'23 * z3 + b'2;      
        z1' = h'(a1);  
        z2' = h'(a2);  
         
        2. 图示说明
        ![图示说明](https://github.com/ZWtu19/Notes/blob/master/src/pics/第一层->第二层.png)  
        2. 矩阵表示  
        A' = ZW' + B'  
        Z' = h'(A')
        其中:  
        A' = [a1', a2', a3'];  
        Z  = [z1, z2, z3];  
        B' = [b1', b2'];  
        W' = [[w11, w21],
             [w12, w22],
             [w13, w23]]  
          
        3. 代码实现   
        ```python
            W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])
            B2 = np.array([0.1, 0.2])
            print(Z1.shape) # (3,) print(W2.shape) # (3, 2) print(B2.shape) # (2,)
            A2 = np.dot(Z1, W2) + B2 
            Z2 = sigmoid(A2)
        ```  
       
    4. 第二层 -> 输出层
        1. 表达式  
        a1'' = w'11 * z1' + w'12 * z2' b''1;  
        a2'' = w'21 * z1' + w'22 * z2' b''2;       
        y1'' = identity_function(a1'');  
        y2'' = identity_function(a2'');  
        
        2. 图示说明  
        ![图示说明](https://github.com/ZWtu19/Notes/blob/master/src/pics/第二层->输出层.png)  
         
        3. 矩阵表示  
        A'' = ZW'' + B''  
        Z'' = identity_function(A'')
        其中:  
        A'' = [a1'', a2'', a3''];  
        Z''  = [z1', z2', z3'];  
        B'' = [b1'', b2''];  
        W'' = [[w11'', w21''],
             [w12'', w22''],
             [w13'', w23'']]  
         
        4. 代码实现  
        ```python
           def identity_function(x): return x
           W3 = np.array([[0.1, 0.3], [0.2, 0.4]]) B3 = np.array([0.1, 0.2])
           A3 = np.dot(Z2, W3) + B3
           Y = identity_function(A3) # 或者Y = A3                      

        ```
     
* 利用神经网络解决实际问题: 字母识别(详见....)  
    1. 收集数据集  
    2. 推理过程  
    3. 实验结果       
    
#### 3.神经网络的"学习"

##### 从数据中学习  
##### 损失函数  
##### 数值微分  
##### 梯度  
##### 学习算法的实现  

#### 4.误差反向传播学习法
#### 5.卷积神经网络
#### 6.深度学习
